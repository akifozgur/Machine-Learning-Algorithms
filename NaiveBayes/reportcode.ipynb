{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6e1764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import math\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ef73b",
   "metadata": {},
   "source": [
    "## PART I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81b40eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"English_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0143c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df = df[df['Category'] == \"sport\"]\n",
    "business_df = df[df['Category'] == \"business\"]\n",
    "politics_df = df[df['Category'] == \"politics\"]\n",
    "entertainment_df = df[df['Category'] == \"entertainment\"]\n",
    "tech_df = df[df['Category'] == \"tech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a4be904",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df['Text'] = sport_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() ]))\n",
    "business_df['Text'] = business_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split()] ))\n",
    "politics_df['Text'] = politics_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split()] ))\n",
    "entertainment_df['Text'] = entertainment_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split()] ))\n",
    "tech_df['Text'] = tech_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c902ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Commonly Used Words For Each Category \n",
      "\n",
      "Sport:  [('the', 6620), ('to', 3189), ('a', 2651), ('and', 2532), ('in', 2510), ('of', 1826), ('s', 1440), ('i', 1304), ('for', 1127), ('he', 1105), ('on', 1014), ('but', 992), ('is', 985), ('it', 974), ('was', 943), ('that', 863), ('have', 812), ('with', 803), ('at', 794), ('his', 762), ('we', 660), ('has', 650), ('said', 636), ('be', 614), ('will', 575), ('as', 547), ('not', 490), ('from', 481), ('after', 477), ('by', 430), ('they', 414), ('had', 414), ('their', 381), ('been', 363), ('are', 356), ('game', 356), ('an', 353), ('this', 353), ('out', 351), ('first', 350), ('year', 331), ('england', 329), ('who', 324), ('t', 322), ('against', 312), ('time', 296), ('win', 295), ('when', 295), ('up', 294), ('two', 290), ('world', 269), ('all', 268), ('over', 267), ('there', 264), ('back', 263), ('last', 262), ('one', 261), ('if', 255), ('6', 252), ('she', 244), ('you', 244), ('would', 233), ('can', 230), ('before', 225), ('were', 225), ('her', 219), ('also', 214), ('players', 209), ('cup', 206), ('team', 205), ('new', 202), ('my', 199), ('him', 197), ('half', 194), ('ireland', 194), ('side', 193), ('play', 193), ('just', 192), ('m', 192), ('second', 189), ('now', 187), ('o', 184), ('into', 184), ('wales', 183), ('six', 181), ('final', 180), ('match', 180), ('three', 178), ('very', 176), ('won', 175), ('only', 174), ('what', 173), ('me', 171), ('could', 171), ('good', 170), ('so', 169), ('season', 166), ('set', 161), ('which', 160), ('france', 158)] \n",
      "\n",
      "Business:  [('the', 7133), ('to', 3306), ('of', 2864), ('in', 2821), ('a', 2296), ('and', 2161), ('s', 1367), ('said', 1100), ('is', 1072), ('that', 1052), ('for', 1045), ('it', 1011), ('on', 906), ('has', 835), ('its', 736), ('by', 718), ('with', 612), ('at', 609), ('as', 605), ('was', 596), ('from', 588), ('be', 573), ('have', 554), ('are', 538), ('us', 522), ('will', 520), ('year', 456), ('which', 404), ('mr', 393), ('but', 391), ('an', 385), ('had', 343), ('this', 322), ('would', 309), ('been', 307), ('up', 306), ('not', 302), ('more', 298), ('he', 287), ('market', 284), ('were', 282), ('also', 279), ('than', 275), ('new', 273), ('1', 271), ('their', 265), ('firm', 261), ('growth', 257), ('company', 253), ('last', 236), ('economy', 233), ('about', 228), ('after', 221), ('government', 215), ('we', 210), ('bank', 206), ('they', 204), ('economic', 202), ('sales', 201), ('2004', 199), ('over', 198), ('could', 198), ('2', 194), ('one', 183), ('may', 182), ('oil', 179), ('000', 175), ('shares', 171), ('world', 169), ('however', 165), ('two', 164), ('years', 162), ('some', 157), ('chief', 156), ('business', 155), ('deal', 152), ('3', 152), ('now', 151), ('uk', 149), ('if', 147), ('there', 147), ('out', 146), ('financial', 140), ('or', 140), ('china', 140), ('companies', 140), ('5', 138), ('prices', 138), ('other', 136), ('into', 136), ('analysts', 135), ('while', 135), ('2005', 134), ('dollar', 134), ('who', 132), ('4', 132), ('expected', 131), ('against', 127), ('group', 127), ('country', 125)] \n",
      "\n",
      "Politics:  [('the', 7957), ('to', 3913), ('of', 2840), ('and', 2559), ('a', 2532), ('in', 2159), ('said', 1445), ('he', 1410), ('for', 1237), ('that', 1195), ('on', 1186), ('is', 1167), ('be', 1080), ('s', 1074), ('mr', 1073), ('was', 1013), ('it', 998), ('would', 712), ('as', 690), ('have', 669), ('but', 668), ('not', 662), ('by', 651), ('with', 645), ('will', 642), ('are', 635), ('has', 611), ('they', 572), ('at', 564), ('his', 540), ('labour', 494), ('from', 466), ('government', 464), ('had', 462), ('an', 429), ('election', 424), ('we', 416), ('this', 410), ('blair', 395), ('i', 382), ('were', 379), ('been', 377), ('party', 376), ('people', 372), ('there', 364), ('their', 357), ('which', 340), ('who', 330), ('also', 308), ('more', 298), ('if', 289), ('minister', 286), ('up', 284), ('new', 280), ('about', 278), ('could', 272), ('brown', 264), ('uk', 254), ('all', 240), ('or', 229), ('over', 229), ('can', 227), ('should', 222), ('told', 219), ('after', 217), ('out', 213), ('plans', 212), ('no', 206), ('what', 204), ('public', 204), ('its', 200), ('howard', 197), ('prime', 194), ('say', 186), ('one', 185), ('when', 184), ('tax', 184), ('britain', 181), ('being', 179), ('secretary', 178), ('year', 175), ('you', 171), ('tory', 170), ('general', 166), ('only', 166), ('leader', 164), ('t', 163), ('other', 162), ('than', 162), ('says', 159), ('tories', 158), ('some', 156), ('home', 155), ('chancellor', 155), ('so', 153), ('next', 152), ('into', 151), ('do', 151), ('two', 150), ('lord', 150)] \n",
      "\n",
      "Entertainment:  [('the', 5822), ('and', 2130), ('to', 2108), ('of', 2048), ('in', 1996), ('a', 1898), ('s', 1247), ('for', 1097), ('on', 881), ('was', 818), ('it', 738), ('is', 684), ('with', 662), ('said', 594), ('he', 584), ('film', 583), ('at', 554), ('be', 502), ('that', 491), ('as', 479), ('has', 471), ('his', 460), ('by', 460), ('will', 433), ('best', 430), ('i', 424), ('have', 384), ('who', 358), ('from', 356), ('are', 331), ('but', 326), ('year', 315), ('which', 305), ('an', 299), ('also', 277), ('been', 276), ('this', 266), ('one', 265), ('us', 264), ('had', 263), ('were', 262), ('music', 255), ('not', 251), ('they', 241), ('she', 240), ('we', 236), ('their', 235), ('new', 234), ('up', 225), ('show', 222), ('her', 215), ('first', 188), ('after', 186), ('awards', 184), ('more', 177), ('uk', 171), ('its', 171), ('actor', 169), ('number', 165), ('won', 164), ('band', 162), ('out', 162), ('last', 160), ('star', 160), ('director', 159), ('all', 156), ('award', 152), ('mr', 151), ('there', 151), ('two', 149), ('other', 145), ('t', 145), ('tv', 142), ('top', 141), ('films', 138), ('would', 138), ('about', 137), ('time', 136), ('years', 135), ('or', 134), ('british', 133), ('when', 133), ('you', 130), ('than', 130), ('while', 130), ('three', 129), ('people', 127), ('bbc', 125), ('album', 125), ('including', 116), ('actress', 116), ('oscar', 112), ('chart', 112), ('singer', 109), ('into', 108), ('made', 101), ('no', 100), ('festival', 100), ('so', 100), ('world', 99)] \n",
      "\n",
      "Tech:  [('the', 7498), ('to', 4149), ('of', 3425), ('and', 3017), ('a', 2773), ('in', 2316), ('that', 1676), ('is', 1597), ('it', 1465), ('for', 1299), ('on', 1111), ('said', 1064), ('be', 1057), ('are', 994), ('as', 929), ('s', 806), ('will', 797), ('with', 787), ('have', 731), ('by', 727), ('has', 686), ('was', 653), ('people', 647), ('they', 630), ('more', 624), ('not', 535), ('at', 533), ('but', 527), ('which', 514), ('from', 500), ('he', 484), ('can', 480), ('this', 474), ('or', 452), ('their', 422), ('up', 413), ('an', 408), ('its', 388), ('about', 371), ('one', 351), ('you', 351), ('new', 349), ('mr', 349), ('also', 348), ('were', 344), ('mobile', 343), ('than', 343), ('we', 336), ('would', 322), ('been', 312), ('could', 308), ('technology', 303), ('there', 277), ('users', 268), ('software', 265), ('such', 263), ('out', 260), ('use', 260), ('other', 259), ('net', 256), ('music', 255), ('all', 255), ('us', 253), ('year', 251), ('digital', 244), ('many', 237), ('so', 235), ('what', 234), ('phone', 227), ('games', 227), ('them', 223), ('make', 217), ('some', 217), ('like', 216), ('had', 215), ('if', 210), ('now', 208), ('who', 206), ('i', 205), ('do', 204), ('service', 202), ('over', 198), ('uk', 196), ('computer', 196), ('time', 196), ('microsoft', 196), ('online', 191), ('used', 189), ('when', 188), ('just', 186), ('into', 186), ('first', 184), ('million', 183), ('world', 183), ('video', 181), ('get', 179), ('internet', 179), ('tv', 176), ('being', 174), ('way', 173)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"100 Most Commonly Used Words For Each Category\",\"\\n\")\n",
    "print(\"Sport: \",Counter(\" \".join(sport_df[\"Text\"]).split()).most_common(100),\"\\n\")\n",
    "print(\"Business: \",Counter(\" \".join(business_df[\"Text\"]).split()).most_common(100),\"\\n\")\n",
    "print(\"Politics: \",Counter(\" \".join(politics_df[\"Text\"]).split()).most_common(100),\"\\n\")\n",
    "print(\"Entertainment: \",Counter(\" \".join(entertainment_df[\"Text\"]).split()).most_common(100),\"\\n\")\n",
    "print(\"Tech: \",Counter(\" \".join(tech_df[\"Text\"]).split()).most_common(100),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f26808",
   "metadata": {},
   "source": [
    "In this part, we divided the texts that we pulled from the dataset into words one by one. Then, we have listed the 100 most commonly used words in their categories above. Below we have listed 3 words that are most common for one category, but not so common for other categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c92bed",
   "metadata": {},
   "source": [
    "Sports ('game', 356) ('win', 295) ('cup', 206)\n",
    "<br>\n",
    "Business ('market', 284) ('firm', 261) ('growth', 257)\n",
    "<br>\n",
    "Politics ('labour', 494) ('government', 464) ('election', 424)\n",
    "<br>\n",
    "Entertainment ('film', 583) ('music', 255) ('awards', 184)\n",
    "<br>\n",
    "Tech ('mobile', 343) ('technology', 303) ('users', 268)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca2adf8",
   "metadata": {},
   "source": [
    "## PART II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "381da45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_edit_dataset(dataset):\n",
    "    df = pd.read_csv(dataset).drop([\"ArticleId\"],axis=1).sample(frac=1)\n",
    "    df['Text'] = df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z]\", \" \", word.lower()) for word in x.split() ]))\n",
    "    texts = df['Text'].values\n",
    "    categories = df['Category'].values\n",
    "    labels = list(set(categories))\n",
    "    return texts,categories,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f72e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(texts,categories):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(texts, categories, test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f164389",
   "metadata": {},
   "source": [
    "##### Bag Of Words\n",
    "A bag-of-words model, or BoW for short, is a way of extracting features from text for use in modeling, such as with machine learning algorithms. The approach is very simple and flexible, and can be used in a myriad of ways for extracting features from documents.\n",
    "\n",
    "A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n",
    "\n",
    "1. A vocabulary of known words.\n",
    "2. A measure of the presence of known words.\n",
    "\n",
    "It is called a “bag” of words, because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ad21357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_BoW(X_train, y_train, labels, slice_percent=70, tf_idf_transformer=False, stopwords=False, option=\"unigram\"):\n",
    "    \n",
    "    if(stopwords):\n",
    "        if (option==\"unigram\"):\n",
    "            vectorizer = CountVectorizer(ngram_range=(1,1),stop_words=ENGLISH_STOP_WORDS)\n",
    "        else:\n",
    "            vectorizer = CountVectorizer(ngram_range=(2,2),stop_words=ENGLISH_STOP_WORDS)\n",
    "            \n",
    "    else:\n",
    "        if (option==\"unigram\"):\n",
    "            vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "        else:\n",
    "            vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "        \n",
    "    X = vectorizer.fit_transform(X_train)\n",
    "        \n",
    "    if (tf_idf_transformer):\n",
    "        tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "        tfidf_transformer.fit(X)\n",
    "        tfidf_dict = dict(zip(vectorizer.get_feature_names(), tfidf_transformer.idf_))\n",
    "        sorted_tfidf_dict = dict(sorted(tfidf_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "        vocabulary = list(sorted_tfidf_dict.keys())[:int(len(sorted_tfidf_dict.keys()) * slice_percent/100)]         \n",
    "        vocabulary = np.array([item for item in vectorizer.get_feature_names() if item in vocabulary])\n",
    "        \n",
    "        X_train_copy=X_train.copy()\n",
    "        for i in range(len(X_train_copy)):\n",
    "            X_train_copy[i] = ' '.join([word for word in X_train_copy[i].split() if word in vocabulary])\n",
    "               \n",
    "        X = vectorizer.fit_transform(X_train_copy)\n",
    "    else:\n",
    "        vocabulary = vectorizer.get_feature_names()\n",
    "        \n",
    "    X = X.toarray()\n",
    "    words_and_counts = {}\n",
    "    for l in labels:\n",
    "        words_and_counts[l] = defaultdict(lambda: 0)\n",
    "    for i in range(X.shape[0]):\n",
    "        l = y_train[i]\n",
    "        for j in range(len(vocabulary)):\n",
    "            words_and_counts[l][vocabulary[j]] += X[i][j]\n",
    "    return words_and_counts,vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f541c70",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier\n",
    "\n",
    "A Naive Bayes classifier is a probabilistic machine learning model that’s used for classification task. The crux of the classifier is based on the Bayes theorem.\n",
    "\n",
    "Using Bayes theorem, we can find the probability of A happening, given that B has occurred. Here, B is the evidence and A is the hypothesis. The assumption made here is that the predictors/features are independent. That is presence of one particular feature does not affect the other. Hence it is called naive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9dbb7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self,labels):\n",
    "        self.labels=labels\n",
    "    \n",
    "    def laplace_smoothing(self,n_label_items, vocabulary, word_counts, word, text_label):\n",
    "        a = word_counts[text_label][word] + 1\n",
    "        b = n_label_items[text_label] + len(vocabulary)\n",
    "        return math.log(a/b)\n",
    "\n",
    "    def group_by_label(self,x, y):\n",
    "        data = {}\n",
    "        for l in self.labels:\n",
    "            data[l] = x[np.where(y == l)]\n",
    "        return data\n",
    "    \n",
    "    def fit(self,x, y):\n",
    "        n_label_items = {}\n",
    "        log_label_priors = {}\n",
    "        n = len(x)\n",
    "        grouped_data = self.group_by_label(x, y)\n",
    "        for l, data in grouped_data.items():\n",
    "            n_label_items[l] = len(data)\n",
    "            log_label_priors[l] = math.log(n_label_items[l] / n)\n",
    "        return n_label_items, log_label_priors\n",
    "\n",
    "    def predict(self,n_label_items, vocabulary, word_counts, log_label_priors, x_test, option=\"unigram\"):\n",
    "        result = []\n",
    "        for text in x_test:\n",
    "            label_scores = {l: log_label_priors[l] for l in self.labels}\n",
    "            if (option == \"unigram\"):\n",
    "                words = set(text.split())\n",
    "            else:\n",
    "                words = text.split()\n",
    "                words = [words[n:n+2] for n in range(0, len(words), 2)]\n",
    "                new_words = list()\n",
    "                for i in words:\n",
    "                    new_words.append(' '.join(map(str, i)))\n",
    "                    \n",
    "                words=new_words\n",
    "                \n",
    "            for word in words:\n",
    "                if word not in vocabulary: continue\n",
    "                for l in self.labels:\n",
    "                    log_w_given_l = self.laplace_smoothing(n_label_items, vocabulary, word_counts, word, l)\n",
    "                    label_scores[l] += log_w_given_l\n",
    "\n",
    "            result.append(max(label_scores, key=label_scores.get))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f220d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, categories, labels = read_and_edit_dataset(\"English_Dataset.csv\")\n",
    "X_train, X_test, y_train, y_test = split_data(texts, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18400703",
   "metadata": {},
   "source": [
    "The accuracy value when we use BoW with \"unigram\" while not using TF-IDF or stop words for our word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c71fe869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Accuracy :  0.9060402684563759\n"
     ]
    }
   ],
   "source": [
    "unigram_words_and_counts, vocabulary = execute_BoW(X_train,y_train,labels,option=\"unigram\")\n",
    "naive_bayes = NaiveBayes(labels)\n",
    "label_items, log_label_priors = naive_bayes.fit(X_train,y_train)\n",
    "unigram_y_pred = naive_bayes.predict(label_items, vocabulary, unigram_words_and_counts, log_label_priors, X_test,option=\"unigram\")\n",
    "print(\"Unigram Accuracy : \", accuracy_score(y_test,unigram_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c174ee",
   "metadata": {},
   "source": [
    "The accuracy value when we use BoW with \"bigram\" while not using TF-IDF or stop words for our word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df7c44cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Accuracy :  0.8993288590604027\n"
     ]
    }
   ],
   "source": [
    "bigram_words_and_counts, vocabulary = execute_BoW(X_train,y_train,labels,option=\"bigram\")\n",
    "naive_bayes = NaiveBayes(labels)\n",
    "label_items, log_label_priors = naive_bayes.fit(X_train,y_train)\n",
    "bigram_y_pred = naive_bayes.predict(label_items, vocabulary, bigram_words_and_counts, log_label_priors, X_test,option=\"biagram\")\n",
    "print(\"Bigram Accuracy : \", accuracy_score(y_test,bigram_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ccb5e9",
   "metadata": {},
   "source": [
    "## PART III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70677516",
   "metadata": {},
   "source": [
    "   ####  Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58250fbf",
   "metadata": {},
   "source": [
    "Term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d488102",
   "metadata": {},
   "source": [
    "We calculated the weights of the words in the texts using TF-IDF and retrained our model by removing the 10% with the lowest weight from our word list. In this way, the terms that allowed us to determine better the categories of the articles remained in the word list that we used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0a132",
   "metadata": {},
   "source": [
    "Increasing or decreasing this percentage gave us worse accuracy results than we have now. For example, if we removed the 90% part with less weight, this time we would have very few words to train the model and our accuracy value would decrease. Or, on the contrary, if we removed the less weighted 1%, this time, the words common in each category would remain in our word list and our accuracy value would decrease again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c970997",
   "metadata": {},
   "source": [
    "By using TF-IDF in the most optimal way, we have increased the accuracy value we obtained without using it at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c2760",
   "metadata": {},
   "source": [
    "The accuracy value when we use TF-IDF but not stop words for our word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55d09afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Accuracy :  0.930648769574944\n"
     ]
    }
   ],
   "source": [
    "words_and_counts, vocabulary= execute_BoW(X_train, y_train, labels, slice_percent=90, tf_idf_transformer=True)\n",
    "naive_bayes = NaiveBayes(labels)\n",
    "label_items, log_label_priors = naive_bayes.fit(X_train,y_train)\n",
    "y_pred = naive_bayes.predict(label_items, vocabulary, words_and_counts, log_label_priors, X_test)\n",
    "print(\"TF-IDF Accuracy : \", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd9f1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df_voc = df[df['Category'] == \"sport\"]\n",
    "business_df_voc = df[df['Category'] == \"business\"]\n",
    "politics_df_voc = df[df['Category'] == \"politics\"]\n",
    "entertainment_df_voc = df[df['Category'] == \"entertainment\"]\n",
    "tech_df_voc = df[df['Category'] == \"tech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac9c4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df_voc['Text'] = sport_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary ]))\n",
    "business_df_voc['Text'] = business_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))\n",
    "politics_df_voc['Text'] = politics_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))\n",
    "entertainment_df_voc['Text'] = entertainment_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))\n",
    "tech_df_voc['Text'] = tech_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8556d52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Words Whose Presence Most Strongly Sredicts \n",
      "\n",
      "Sport:  [('roddick', 97), ('ferguson', 62), ('nadal', 59), ('mourinho', 58), ('holmes', 57), ('wenger', 55), ('newcastle', 53), ('gara', 48), ('athletics', 47), ('hewitt', 46)] \n",
      "\n",
      "Business:  [('yukos', 122), ('airline', 57), ('gm', 55), ('worldcom', 54), ('mci', 53), ('deutsche', 53), ('glazer', 51), ('lse', 51), ('imf', 50), ('ebbers', 45)] \n",
      "\n",
      "Politics:  [('ukip', 101), ('kilroy', 88), ('asylum', 80), ('silk', 79), ('wage', 56), ('minimum', 55), ('clarke', 54), ('blunkett', 49), ('advice', 46), ('hunting', 45)] \n",
      "\n",
      "Entertainment:  [('foxx', 48), ('vera', 40), ('sideways', 40), ('drake', 39), ('lee', 39), ('elvis', 38), ('staunton', 35), ('novel', 34), ('swank', 34), ('concert', 33)] \n",
      "\n",
      "Tech:  [('spam', 99), ('gadget', 87), ('bt', 79), ('spyware', 67), ('mac', 63), ('blogs', 62), ('definition', 59), ('nintendo', 58), ('ipod', 53), ('xbox', 52)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"10 Words Whose Presence Most Strongly Sredicts\",\"\\n\")\n",
    "print(\"Sport: \",Counter(\" \".join(sport_df_voc[\"Text\"]).split()).most_common(10),\"\\n\")\n",
    "print(\"Business: \",Counter(\" \".join(business_df_voc[\"Text\"]).split()).most_common(10),\"\\n\")\n",
    "print(\"Politics: \",Counter(\" \".join(politics_df_voc[\"Text\"]).split()).most_common(10),\"\\n\")\n",
    "print(\"Entertainment: \",Counter(\" \".join(entertainment_df_voc[\"Text\"]).split()).most_common(10),\"\\n\")\n",
    "print(\"Tech: \",Counter(\" \".join(tech_df_voc[\"Text\"]).split()).most_common(10),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3350c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df_not_voc = df[df['Category'] == \"sport\"]\n",
    "business_df_not_voc = df[df['Category'] == \"business\"]\n",
    "politics_df_not_voc = df[df['Category'] == \"politics\"]\n",
    "entertainment_df_not_voc = df[df['Category'] == \"entertainment\"]\n",
    "tech_df_not_voc = df[df['Category'] == \"tech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b97c1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df_not_voc['Text'] = sport_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary and word not in ENGLISH_STOP_WORDS]))\n",
    "business_df_not_voc['Text'] = business_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if (word in vocabulary and word not in ENGLISH_STOP_WORDS)]))\n",
    "politics_df_not_voc['Text'] = politics_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if (word in vocabulary and word not in ENGLISH_STOP_WORDS)]))\n",
    "entertainment_df_not_voc['Text'] = entertainment_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary and word not in ENGLISH_STOP_WORDS]))\n",
    "tech_df_not_voc['Text'] = tech_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if (word in vocabulary and word not in ENGLISH_STOP_WORDS)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76fa5422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Words Whose Absence Most Strongly Sredicts \n",
      "\n",
      "Sport:  [('cent', 1), ('harbours', 1), ('telegraph', 1), ('prolonged', 1), ('shelf', 1), ('pledge', 1), ('scotch', 1), ('spectacular', 1), ('ambitious', 1), ('satisfy', 1)] \n",
      "\n",
      "Business:  [('patterns', 1), ('eat', 1), ('gregg', 1), ('virgin', 1), ('chennai', 1), ('nadu', 1), ('desperately', 1), ('chung', 1), ('mong', 1), ('koo', 1)] \n",
      "\n",
      "Politics:  [('astonishment', 1), ('beggared', 1), ('principally', 1), ('spanning', 1), ('csa', 1), ('knighthoods', 1), ('undertook', 1), ('respectively', 1), ('natwest', 1), ('exams', 1)] \n",
      "\n",
      "Entertainment:  [('motor', 1), ('motors', 1), ('competitions', 1), ('click', 1), ('reliance', 1), ('compact', 1), ('formats', 1), ('tastes', 1), ('outgoing', 1), ('cleaner', 1)] \n",
      "\n",
      "Tech:  [('expanded', 1), ('sealing', 1), ('unwelcome', 1), ('replaces', 1), ('randomly', 1), ('tailed', 1), ('sharply', 1), ('reviewing', 1), ('procedures', 1), ('defacement', 1)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"10 Words Whose Absence Most Strongly Sredicts\",\"\\n\")\n",
    "print(\"Sport: \",Counter(\" \".join(sport_df_not_voc[\"Text\"]).split()).most_common()[-10:],\"\\n\")\n",
    "print(\"Business: \",Counter(\" \".join(business_df_not_voc[\"Text\"]).split()).most_common()[-10:],\"\\n\")\n",
    "print(\"Politics: \",Counter(\" \".join(politics_df_not_voc[\"Text\"]).split()).most_common()[-10:],\"\\n\")\n",
    "print(\"Entertainment: \",Counter(\" \".join(entertainment_df_not_voc[\"Text\"]).split()).most_common()[-10:],\"\\n\")\n",
    "print(\"Tech: \",Counter(\" \".join(tech_df_not_voc[\"Text\"]).split()).most_common()[-10:],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452e09f",
   "metadata": {},
   "source": [
    "   ####  Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f46894",
   "metadata": {},
   "source": [
    "Stop words are the words in a stop list (or stoplist or negative dictionary) which are filtered out (i.e. stopped) before or after processing of natural language data (text) because they are insignificant.[1] There is no single universal list of stop words used by all natural language processing tools, nor any agreed upon rules for identifying stop words, and indeed not all tools even use such a list. Therefore, any group of words can be chosen as the stop words for a given purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1422ccf",
   "metadata": {},
   "source": [
    "In this model, we used Scikit Learn's stop words as stop words. Using these words, we have removed the words that are commonly used to make sentences in English and that does not give us any information to separate the categories from our word list. In this way, we trained our model with a word list of words that are less in number and more informative to distinguish between categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4247980",
   "metadata": {},
   "source": [
    "When we trained our model with the word list from which stop words were removed, we saw that it gave better accuracy than both the model trained with the word list we created without any elimination and the model trained with the word list created with TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cfbcf1",
   "metadata": {},
   "source": [
    "The accuracy value when we use stop words but not TF-IDF for our word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6343af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words Accuracy :  0.9351230425055929\n"
     ]
    }
   ],
   "source": [
    "words_and_counts, vocabulary= execute_BoW(X_train, y_train, labels, stopwords=True)\n",
    "naive_bayes = NaiveBayes(labels)\n",
    "label_items, log_label_priors = naive_bayes.fit(X_train,y_train)\n",
    "y_pred = naive_bayes.predict(label_items, vocabulary, words_and_counts, log_label_priors, X_test)\n",
    "print(\"Stop Words Accuracy : \", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70b301b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df_sw = df[df['Category'] == \"sport\"]\n",
    "business_df_sw = df[df['Category'] == \"business\"]\n",
    "politics_df_sw = df[df['Category'] == \"politics\"]\n",
    "entertainment_df_sw = df[df['Category'] == \"entertainment\"]\n",
    "tech_df_sw = df[df['Category'] == \"tech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73db55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df_sw['Text'] = sport_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))\n",
    "business_df_sw['Text'] = business_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))\n",
    "politics_df_sw['Text'] = politics_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))\n",
    "entertainment_df_sw['Text'] = entertainment_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))\n",
    "tech_df_sw['Text'] = tech_df['Text'].apply(lambda x: ' '.join([re.sub(r\"[^a-zA-Z0-9]\", \" \", word.lower()) for word in x.split() if word in vocabulary]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ad00f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Non-Stopwords That Most Strongly Predict \n",
      "\n",
      "Sport:  [('said', 636), ('game', 356), ('year', 331), ('england', 329), ('time', 296), ('win', 295), ('world', 269), ('players', 209), ('cup', 206), ('team', 205)] \n",
      "\n",
      "Business:  [('said', 1100), ('year', 456), ('mr', 393), ('market', 284), ('new', 273), ('firm', 261), ('growth', 257), ('company', 253), ('economy', 233), ('government', 215)] \n",
      "\n",
      "Politics:  [('said', 1445), ('mr', 1073), ('labour', 494), ('government', 464), ('election', 424), ('blair', 395), ('party', 376), ('people', 372), ('minister', 286), ('new', 280)] \n",
      "\n",
      "Entertainment:  [('said', 594), ('film', 583), ('best', 430), ('year', 315), ('music', 255), ('new', 234), ('awards', 184), ('uk', 171), ('actor', 169), ('number', 165)] \n",
      "\n",
      "Tech:  [('said', 1064), ('people', 647), ('new', 349), ('mr', 349), ('mobile', 343), ('technology', 303), ('users', 268), ('software', 265), ('use', 260), ('net', 256)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"10 Non-Stopwords That Most Strongly Predict\",\"\\n\")\n",
    "print(\"Sport: \",Counter(\" \".join(sport_df_sw[\"Text\"]).split()).most_common(10),\"\\n\")\n",
    "print(\"Business: \",Counter(\" \".join(business_df_sw[\"Text\"]).split()).most_common(10),\"\\n\")\n",
    "print(\"Politics: \",Counter(\" \".join(politics_df_sw[\"Text\"]).split()).most_common(10),\"\\n\")\n",
    "print(\"Entertainment: \",Counter(\" \".join(entertainment_df_sw[\"Text\"]).split()).most_common(10),\"\\n\")\n",
    "print(\"Tech: \",Counter(\" \".join(tech_df_sw[\"Text\"]).split()).most_common(10),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece190d",
   "metadata": {},
   "source": [
    "## PART IV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00968671",
   "metadata": {},
   "source": [
    "In this part, we trained our model with the word list that we created using both TF-IDF and stop words. Our model trained with our word list created with these two features gave higher accuracy than the models trained with other word lists. In this way, we have shown with numerical data that we have narrowed our word list in the most optimal way for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138969a",
   "metadata": {},
   "source": [
    "The accuracy value when we use stop words and TF-IDF for our word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4200231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9463087248322147\n"
     ]
    }
   ],
   "source": [
    "words_and_counts, vocabulary= execute_BoW(X_train, y_train, labels,slice_percent=90, tf_idf_transformer=True, stopwords=True)\n",
    "naive_bayes = NaiveBayes(labels)\n",
    "label_items, log_label_priors = naive_bayes.fit(X_train,y_train)\n",
    "y_pred = naive_bayes.predict(label_items, vocabulary, words_and_counts, log_label_priors, X_test)\n",
    "print(\"Accuracy : \", accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
