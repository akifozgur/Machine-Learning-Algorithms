{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the KNN Algorithm Without Using External Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's add the Numpy and Pandas libraries to our workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's add our Iris dataset to our work using the Pandas library, and simplify and shuffle the created dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n",
       "88             5.6           3.0            4.1           1.3  Iris-versicolor\n",
       "1              4.9           3.0            1.4           0.2      Iris-setosa\n",
       "135            7.7           3.0            6.1           2.3   Iris-virginica\n",
       "7              5.0           3.4            1.5           0.2      Iris-setosa\n",
       "87             6.3           2.3            4.4           1.3  Iris-versicolor\n",
       "..             ...           ...            ...           ...              ...\n",
       "68             6.2           2.2            4.5           1.5  Iris-versicolor\n",
       "107            7.3           2.9            6.3           1.8   Iris-virginica\n",
       "48             5.3           3.7            1.5           0.2      Iris-setosa\n",
       "70             5.9           3.2            4.8           1.8  Iris-versicolor\n",
       "13             4.3           3.0            1.1           0.1      Iris-setosa\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df.drop(\"Id\",inplace=True,axis=1)\n",
    "df = df.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function called 'split_data' to separate the data into 'train' and 'test' sets. This function takes parameters: a numpy array 'X' containing the features of flowers, a numpy array 'y' containing the class labels of the flowers, and a percentage value 'train_size' indicating the proportion in which the data will be split into 'train' and 'test' sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_size):\n",
    "\n",
    "    start = int(len(X)*train_size)\n",
    "\n",
    "    X_train = X[0:start, :]\n",
    "    X_test = X[start:-1, :]\n",
    "    y_train = y[0:start]\n",
    "    y_test = y[start:-1]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to create the K-Nearest Neighbors Algorithm. Let's take a look at the functions we have created within the KNN class in order:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at the 'euclidean_distance' and 'manhattan_distance' functions. These functions calculate the distances between all corresponding features of a given test and train data, provided as parameters. They sum up these distances and return the result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another function we have is the \"predict\" function. This function calculates the distances between each test data and each training data, storing them in a list called \"distance\" along with the indices of the compared training data. Then, it sorts the distances in ascending order from closest to farthest. After that, it keeps only the first \"k\" distances in the list and removes the others. Now, the list contains only the closest \"k\" distances and their corresponding indices in the training arrays. By adding the classes of these indices in the \"y_train\" to a list called \"neighbors,\" we attempt to predict the class of the flower with the closest features among the top \"k\" flowers. Subsequently, based on the class with the highest frequency in the \"neighbors\" list, we predict the class of the flower we are trying to predict. Finally, we gather these predictions in a list called \"predicted_classes\" and return that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "\n",
    "    def __init__(self, k, distance_type):\n",
    "        self.distance_type = distance_type\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        assert len(X) == len(y)\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def euclidean_distance(self, X1, X2):\n",
    "\n",
    "        distance = 0\n",
    "        for i in range(len(X1)):\n",
    "            distance += (X1[i] - X2[i]) ** 2\n",
    "        return np.sqrt(distance)\n",
    "\n",
    "    def manhattan_distance(self, X1, X2):\n",
    "        distance = np.abs(np.array(X1) - np.array(X2)).sum()\n",
    "        return distance\n",
    "\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        predicted_classes = []\n",
    "        \n",
    "        for test_data_index in range(len(X_test)):\n",
    "            \n",
    "            distances = []\n",
    "            for train_data_index in range(len(self.X_train)):\n",
    "                if (self.distance_type == \"euclidean\"):\n",
    "                    distance = self.euclidean_distance(self.X_train[train_data_index], X_test[test_data_index])\n",
    "                elif (self.distance_type == \"manhattan\"):\n",
    "                    distance = self.manhattan_distance(self.X_train[train_data_index], X_test[test_data_index])\n",
    "                distances.append([distance, train_data_index])\n",
    "            distances.sort()\n",
    "            distances = distances[0:self.k]\n",
    "            neighbors = []\n",
    "            for distance, train_data_index in distances:\n",
    "                neighbors.append(self.y_train[train_data_index])\n",
    "\n",
    "            predicted_class = max(set(neighbors), key=neighbors.count)\n",
    "            predicted_classes.append(predicted_class)\n",
    "            \n",
    "        return predicted_classes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Accuracy metric to measure the accuracy of our predictions. Accuracy is calculated by dividing the number of correctly predicted instances for all classes by the total number of test instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acuracy(actual, predictions):\n",
    "\n",
    "    assert len(actual) == len(predictions)\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    print(\"Acuracy of kNN model : \",correct / float(len(actual)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign the columns containing the characteristics of flowers in the DataFrame to a variable named \"X,\" and the columns containing the classes of flowers to a variable named \"y\" as numpy arrays. Then, let's pass these numpy arrays as parameters to the function called \"split_data\" that we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:,0:-1])\n",
    "y = np.array(df.iloc[:,-1:]).reshape((-1,))\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n",
      "Acuracy of kNN model :  0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "distance=\"manhattan\"\n",
    "knn = KNN(k,distance)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Manhattan\")\n",
    "print_acuracy(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n",
      "Acuracy of kNN model :  0.9772727272727273\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "distance=\"euclidean\"\n",
    "knn = KNN(k,distance)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Euclidean\")\n",
    "print_acuracy(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the K-Nearest Neighbors Algorithm Using the Scikit-Learn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5,metric=\"manhattan\")\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(\"Manhattan\")\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5,metric=\"euclidean\")\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(\"Euclidean\")\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e69cf1ed2b9e108095e9dfcb8f8814381919d36e7e7b4c88a4a85b3d45aa9055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
