{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En Yakın K Komşu Algoritması"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Özel Kütüphane Kullanmadan KNN Algoritmasını Gerçekleştirme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk önce Numpy ve Pandas Kütüphanelerini çalışmamıza ekleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ardından Iris veri setimizi Pandas kütüphanesi yardımıyla çalışmamıza ekleyelim ve oluşturduğumuz dataframe'i sadeleştirip karıştıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n",
       "88             5.6           3.0            4.1           1.3  Iris-versicolor\n",
       "1              4.9           3.0            1.4           0.2      Iris-setosa\n",
       "135            7.7           3.0            6.1           2.3   Iris-virginica\n",
       "7              5.0           3.4            1.5           0.2      Iris-setosa\n",
       "87             6.3           2.3            4.4           1.3  Iris-versicolor\n",
       "..             ...           ...            ...           ...              ...\n",
       "68             6.2           2.2            4.5           1.5  Iris-versicolor\n",
       "107            7.3           2.9            6.3           1.8   Iris-virginica\n",
       "48             5.3           3.7            1.5           0.2      Iris-setosa\n",
       "70             5.9           3.2            4.8           1.8  Iris-versicolor\n",
       "13             4.3           3.0            1.1           0.1      Iris-setosa\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df.drop(\"Id\",inplace=True,axis=1) # Model için kullanmayacağımız sütunları dataframe'den çıkaralım.\n",
    "df = df.sample(frac=1) # Dataframe'i karıştıralım.\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verileri \"train\" ve \"test\" olarak ayırmak için \"split_data\" adında bir fonksiyon oluşturalım. Bu fonksiyon parametre olarak çiçeklerin özelliklerini içeren bir \"X\" numpy dizisi, çiçeklerin hangi sınıflara ait olduklarını içeren bir \"y\" numpy dizisi ve hangi oranda \"train\" ve \"test\" olarak ayırılacaklarına dair \"train_size\" adında bir yüzdelik değer alır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_size):\n",
    "\n",
    "    start = int(len(X)*train_size)\n",
    "\n",
    "    X_train = X[0:start, :]\n",
    "    X_test = X[start:-1, :]\n",
    "    y_train = y[0:start]\n",
    "    y_test = y[start:-1]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi sıra En Yakın K Komşu Algoritma'sını oluşturmaya geldi. Sırayla KNN sınıfı içinde oluşturduğumuz fonksiyonlara bir göz atalım;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk olarak \"euclidean_distance ve manhattan_distance\" fonksiyonlarına bakalım. Bu fonksiyonlar kendisine parametre olarak gelen birer adet test ve train verisinin karşılıklı bütün özelliklerinin arasındaki mesafeleri bulur ve bu mesafeleri toplayarak geri döndürür."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diğer bir fonksiyonumuz ise \"predict\" fonksiyonu. Bu fonksiyon her bir test verisinin her bir train verisi ile arasındaki mesafeleri, karşılaştırılan train verilerinin dizinleriyle birlikte \"distance\" adında bir listede saklar. Ardından bu \"distance\" listesindeki mesafeleri yakından uzağa (küçükten büyüğe) doğru sıralar. Sonrasında ilk \"k\" sayısı kadarını liste içinde tutar ve diğerlerini listeden çıkarır. Artık listede sadece en yakın \"k\" kadar mesafe ve o mesafelerin train dizilerindeki dizinleri kalmıştır. İşte bu dizinlerin \"y_train\" de karşılık geldikleri sınıfları \"neighbors\" adlı bir listeye ekleyerek tahmin etmeye çalıştığımız çiçeğe en yakın özelliklere sahip en yakın \"k\" kadar çiçeğin sınıfını bulmuş oluruz. Ardından \"neighbors\" adlı listede hangi sınıf sayısı fazla ise sınıfını tahmin etmeye çalıştığımız çiçeği o sınıfın üyesi olarak tahmin ederiz. Ardından bu tahminlerimizi \"predicted_classes\" adlı bir listede toplarız ve o listeyi döndürürüz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "\n",
    "    def __init__(self, k, distance_type):\n",
    "        self.distance_type = distance_type\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        assert len(X) == len(y)\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def euclidean_distance(self, X1, X2):\n",
    "\n",
    "        distance = 0\n",
    "        for i in range(len(X1)):\n",
    "            distance += (X1[i] - X2[i]) ** 2\n",
    "        return np.sqrt(distance)\n",
    "\n",
    "    def manhattan_distance(self, X1, X2):\n",
    "        distance = np.abs(np.array(X1) - np.array(X2)).sum()\n",
    "        return distance\n",
    "\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        predicted_classes = []\n",
    "        \n",
    "        for test_data_index in range(len(X_test)):\n",
    "            \n",
    "            distances = []\n",
    "            for train_data_index in range(len(self.X_train)):\n",
    "                if (self.distance_type == \"euclidean\"):\n",
    "                    distance = self.euclidean_distance(self.X_train[train_data_index], X_test[test_data_index])\n",
    "                elif (self.distance_type == \"manhattan\"):\n",
    "                    distance = self.manhattan_distance(self.X_train[train_data_index], X_test[test_data_index])\n",
    "                distances.append([distance, train_data_index])\n",
    "            distances.sort()\n",
    "            distances = distances[0:self.k]\n",
    "            neighbors = []\n",
    "            for distance, train_data_index in distances:\n",
    "                neighbors.append(self.y_train[train_data_index])\n",
    "\n",
    "            predicted_class = max(set(neighbors), key=neighbors.count)\n",
    "            predicted_classes.append(predicted_class)\n",
    "            \n",
    "        return predicted_classes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaptığımız tahminlerin doğruluğunu ölçmek için Acuracy metriğini kullanacağız. Acuracy, sınıfları doğru tahmin edilen test verisi sayısının toplam test verisi sayısına bölünmesiyle bulunur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acuracy(actual, predictions):\n",
    "\n",
    "    assert len(actual) == len(predictions)\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    print(\"Acuracy of kNN model : \",correct / float(len(actual)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe'de çiçeklerin özelliklerinin bulunduğu sütunları \"X\" adında bir değişkene, çiçeklerin sınıflarının bulunduğu sütunları ise \"y\" adında bir değişkene numpy dizisi olarak atayalım. Ardından bu numpy dizilerini yukarıda oluşturduğumuz \"split_data\" adındaki fonksiyona parametre olarak verelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:,0:-1])\n",
    "y = np.array(df.iloc[:,-1:]).reshape((-1,))\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n",
      "Acuracy of kNN model :  0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "distance=\"manhattan\"\n",
    "knn = KNN(k,distance)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Manhattan\")\n",
    "print_acuracy(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n",
      "Acuracy of kNN model :  0.9772727272727273\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "distance=\"euclidean\"\n",
    "knn = KNN(k,distance)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Euclidean\")\n",
    "print_acuracy(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sckit-Learn Kütüphanesi Kullanarak KNN Algoritmasını Gerçekleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5,metric=\"manhattan\")\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(\"Manhattan\")\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5,metric=\"euclidean\")\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(\"Euclidean\")\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e69cf1ed2b9e108095e9dfcb8f8814381919d36e7e7b4c88a4a85b3d45aa9055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
